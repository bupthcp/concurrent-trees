#summary How to reduce memory usage of trees using NodeFactory

= Introduction =

The trees in this project are not coupled with the implementation of Node objects.

[http://concurrent-trees.googlecode.com/svn/concurrent-trees/javadoc/apidocs/com/googlecode/concurrenttrees/radix/node/Node.html Node] is an interface that algorithms in the trees interact with, and so for any node it is possible to abstract its implementation to reduce memory overhead.

The tree algorithms do not create nodes directly, they request new nodes from a [http://concurrent-trees.googlecode.com/svn/concurrent-trees/javadoc/apidocs/com/googlecode/concurrenttrees/radix/node/NodeFactory.html NodeFactory] supplied to the constructor of the tree. Some basic factories are included (discussed below).

== Memory Reduction Techniques ==

A Java object consumes a minimum of perhaps 32 bytes of RAM, and a reference to the object will consume another 4 or 8 bytes (details [http://www.codeinstructions.com/2008/12/java-objects-memory-structure.html here]). The number of fields and the type of fields in an object additionally increases memory overhead.

The following techniques to reduce memory overhead are mostly applicable to suffix trees built for large keys/documents (such as adding entire documents to the tree as individual keys). This is less applicable to radix trees, which inherently require much less memory even for long documents.

Building suffix trees from large text documents, can require many nodes. For example the `test/` folder in the source, contains tests based on the Collected Works of William Shakespeare (not even considered a large data set by today's standards). A Shakespearean play is approximately 160KB on disk with UTF-8 encoding. A suffix tree for such a play was found to require approximately 133,000 nodes. Java by default stores characters as UTF-16. Storing character data within each node in a suffix tree for such a document requires 11GB or RAM. Storing character data outside the suffix tree and using offset pointers instead, reduces this to ~100MB. Significant additional reductions would be possible. So it is useful that `NodeFactory` abstracts the internal representation of nodes from the algorithms which manipulate them.

Nodes expose the _edges_ within the tree as `CharSequence` objects, and as such they can store character data inside the node - for example as a copied `char[]`, or as start and end offsets onto the original input string.

Two basic implementations of `NodeFactory` are currently provided:
  * [http://concurrent-trees.googlecode.com/svn/concurrent-trees/javadoc/apidocs/com/googlecode/concurrenttrees/radix/node/concrete/NaiveCharArrayNodeFactory.html NaiveCharArrayNodeFactory]
    * Stores character data inside the tree by copying character sequences into a `char[]` stored within each node
    * This can use more memory for large keys or documents added to the tree (especially for suffix trees, less so for radix trees)
    * The advantage of this factory is garbage collection: there is no danger that a large string might be retained in memory by a single node referencing only a small subsequence of the string
  * [http://concurrent-trees.googlecode.com/svn/concurrent-trees/javadoc/apidocs/com/googlecode/concurrenttrees/radix/node/concrete/NaiveCharSequenceNodeFactory.html NaiveCharSequenceNodeFactory]
    * Does not store character data inside the tree, but rather stores pointers to character sequences in the input string, as start and end offsets and a reference to the original string in the node
    * An advantage of this factory is it uses much less memory, especially for suffix trees
    * A disadvantage of this factory is garbage collection: if a large document/key is added to the tree, and then a small document is added to the tree, the nodes added for the small document will re-use edges which were previously added for the large document. If the large document is subsequently removed from the tree, edges which are still in use by the small document will not be removed, and so the large document will not be garbage collected

Both of the node factories above are _naive_, because although they implement those two basic strategies, they do not make any effort to reduce the number of fields within each node. Each factory produces only a single type of node for all use cases, regardless of the data which the algorithms supply to the factory to be stored in the node.

Memory could be reduced further by more sophisticated node factories as follows:
  * Store character data inside nodes as UTF-8 (i.e. single-byte), convert it to 2-byte Java `char` on demand
  * Where an edge contains only two characters (for example), instead of storing a two-character `char[]`, a dedicated implementation of a node could be returned which stores the edge in two primitive `char` fields (`char[]` consumes more memory than primitive fields)
  * Not all nodes are associated with values (the algorithms create nodes to create branches when necessary; nodes created for this purpose are never associated with values). A node factory could return an implementation which does not have a field for storing a value if no value was supplied